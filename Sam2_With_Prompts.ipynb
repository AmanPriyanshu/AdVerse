{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Sf0cLuf-FeRG",
        "cFfmgoNLFgpO"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Sf0cLuf-FeRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyngrok ngrok --force\n",
        "# !ngrok authtoken \"2AtiO9fAGfXvRDmPeuviD2BtA9L_512HFDFcGLVhqR5oPzVUT\"\n",
        "# from ngrok import ngrok\n",
        "\n",
        "# listener = ngrok.connect(\n",
        "#     # session configuration\n",
        "#     addr=\"127.0.0.1:4040\",\n",
        "#     authtoken=\"2AtiO9fAGfXvRDmPeuviD2BtA9L_512HFDFcGLVhqR5oPzVUT\",\n",
        "#     session_metadata=\"Online in One Line\",\n",
        "#     # listener configuration\n",
        "#     metadata=\"example listener metadata from python\",\n",
        "#     domain=\"fancy-basilisk-personally.ngrok-free.app\",\n",
        "#     schemes=[\"HTTPS\"],\n",
        "#     proto=\"http\",\n",
        "#     # module configuration\n",
        "# )"
      ],
      "metadata": {
        "id": "fcC-id-dwTTm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/segment-anything-2.git\n",
        "!cp -r segment-anything-2/* ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZQCAZzX-QK-",
        "outputId": "1197aed9-b4eb-4aed-d836-854d5d61b16d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'segment-anything-2'...\n",
            "remote: Enumerating objects: 510, done.\u001b[K\n",
            "remote: Total 510 (delta 0), reused 0 (delta 0), pack-reused 510 (from 1)\u001b[K\n",
            "Receiving objects: 100% (510/510), 88.46 MiB | 15.55 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAwynwX9Rujf",
        "outputId": "7a40f7f3-2a80-4275-e775-99de8bd9bff4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.45.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.3)\n",
            "Downloading openai-1.45.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.1/374.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.45.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openai_key = userdata.get('yash_openai_api_key')"
      ],
      "metadata": {
        "id": "ysnEGXOtR0UJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything-2.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKdKKu9f-2xS",
        "outputId": "417ed60b-fc43-4a8f-ebaf-e7aa2d538e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/segment-anything-2.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything-2.git to /tmp/pip-req-build-0bpx5r9p\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything-2.git /tmp/pip-req-build-0bpx5r9p\n",
            "  Resolved https://github.com/facebookresearch/segment-anything-2.git to commit 7e1596c0b6462eb1d1ba7e1492430fed95023598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting-up Classes"
      ],
      "metadata": {
        "id": "cFfmgoNLFgpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "class ZeroShotObjectDetector:\n",
        "  def __init__(self, labels):\n",
        "    self.checkpoint = \"google/owlv2-base-patch16-ensemble\"\n",
        "    self.detector = pipeline(model=self.checkpoint, task=\"zero-shot-object-detection\", device=\"cuda\")\n",
        "    self.labels = labels\n",
        "\n",
        "  def reset_labels(self, labels):\n",
        "    self.labels = labels\n",
        "\n",
        "  def apply_on_image(self, image):\n",
        "    image = image.convert(\"RGB\")\n",
        "    predictions = self.detector(\n",
        "        image,\n",
        "        candidate_labels=self.labels,\n",
        "    )\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "z6Rj2iBhE0wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCDFmqXR-MmL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class CustomYOLOSegment:\n",
        "  def __init__(self):\n",
        "    self.predictor = SAM2ImagePredictor.from_pretrained(\"facebook/sam2-hiera-tiny\")\n",
        "\n",
        "  def segment_image(self, input_box, image):\n",
        "    input_box = np.array(input_box)\n",
        "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "      self.predictor.set_image(np.array(image.convert(\"RGB\")))\n",
        "      masks, _, _ = self.predictor.predict(point_coords=None,\n",
        "      point_labels=None,\n",
        "      box=input_box[None, :],\n",
        "      multimask_output=False,)\n",
        "    return masks[0]\n",
        "\n",
        "  def segment_array_of_bboxes(self, array_of_bboxes, image):\n",
        "    masks = []\n",
        "    for input_box in array_of_bboxes:\n",
        "      mask = self.segment_image(input_box, image)\n",
        "      masks.append(mask)\n",
        "    return np.array(masks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def download_image(url, filename):\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Write the content to a file\n",
        "        with open(filename, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"Image successfully downloaded: {filename}\")\n",
        "    else:\n",
        "        print(f\"Failed to download image. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "id": "e7HW4WnBEak3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import cv2\n",
        "\n",
        "class FillWithDalleE:\n",
        "  def __init__(self):\n",
        "    self.client = OpenAI(api_key=openai_key)\n",
        "\n",
        "  def edit_image(self, image, masks, prompt, pred_labels, filenames):\n",
        "    image.save(\"image.png\")\n",
        "    rgb_image = np.array(image.convert(\"RGB\"))\n",
        "    urls = []\n",
        "    for i in range(len(masks)):\n",
        "      rgba_image = np.dstack((rgb_image, 255*(1-masks[i])))\n",
        "      cv2.imwrite(f'mask_images_{i+1}.png', rgba_image)\n",
        "      response = self.client.images.edit(\n",
        "        model=\"dall-e-2\",\n",
        "        image=open(\"image.png\", \"rb\"),\n",
        "        mask=open(f'mask_images_{i+1}.png', \"rb\"),\n",
        "        prompt=prompt+pred_labels[i],\n",
        "        n=1,\n",
        "        size=\"512x512\"\n",
        "      )\n",
        "      image_url = response.data[0].url\n",
        "      download_image(image_url, filenames[i])"
      ],
      "metadata": {
        "id": "y9bn5ePhR4i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Inferences"
      ],
      "metadata": {
        "id": "HjtkMqYvI6vT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"shoe\", \"t-shirt\", \"cap\"]\n",
        "zsod = ZeroShotObjectDetector(labels)\n",
        "cys = CustomYOLOSegment()\n",
        "fwde = FillWithDalleE()"
      ],
      "metadata": {
        "id": "jpuX4qvgJf21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open('kid.png')\n",
        "boxes = zsod.apply_on_image(image)\n",
        "pred_labels = [box['label'] for box in boxes]\n",
        "boxes = [[box['box'][l] for l in ['xmin', 'ymin', 'xmax', 'ymax']] for box in boxes]\n",
        "masks = cys.segment_array_of_bboxes(boxes, image)\n",
        "mask_means = [np.mean(mask) for mask in masks]\n",
        "sorted_items = sorted(zip(mask_means, masks, pred_labels, boxes), key=lambda x: x[0], reverse=True)\n",
        "sorted_mask_means, sorted_masks, sorted_pred_labels, sorted_boxes = zip(*sorted_items)\n",
        "sorted_pred_labels = list(sorted_pred_labels)\n",
        "sorted_boxes = list(sorted_boxes)\n",
        "sorted_masks = np.stack(list(sorted_masks))\n",
        "fwde.edit_image(image, sorted_masks[:4], \"Suggests swift movement and athleticism, with the words \\\"NIKE\\\". This should be placed on a \", sorted_pred_labels, filenames=[\"img_\"+str(i)+\".png\" for i in range(len(sorted_pred_labels))])"
      ],
      "metadata": {
        "id": "RQXPEqaRI8O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Backend"
      ],
      "metadata": {
        "id": "jPNCB9Y5og5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install flask-ngrok\n",
        "!pip install flask-cloudflared"
      ],
      "metadata": {
        "id": "Isbp6bI6qeqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify, send_file\n",
        "# from flask_ngrok import run_with_ngrok\n",
        "from flask_cloudflared import run_with_cloudflared\n",
        "import os\n",
        "import base64\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_cloudflared(app)\n",
        "\n",
        "class Advertiser:\n",
        "    def __init__(self, name, motive, objects_to_advertise):\n",
        "        self.name = name\n",
        "        self.motive = motive\n",
        "        self.objects_to_advertise = objects_to_advertise\n",
        "\n",
        "class Meme:\n",
        "    def __init__(self, name, image_path, masks, pred_labels):\n",
        "        self.name = name\n",
        "        self.image_path = image_path\n",
        "        self.masks = masks\n",
        "        self.pred_labels = pred_labels\n",
        "\n",
        "advertisers = []\n",
        "memes = {}\n",
        "unique_objects = set()\n",
        "\n",
        "zsod = None\n",
        "cys = CustomYOLOSegment()\n",
        "fwde = FillWithDalleE()\n",
        "\n",
        "def update_labels():\n",
        "    global zsod\n",
        "    zsod = ZeroShotObjectDetector(list(unique_objects))\n",
        "\n",
        "@app.route('/advertiser', methods=['POST'])\n",
        "def add_advertiser():\n",
        "    data = request.json\n",
        "    new_advertiser = Advertiser(data['name'], data['motive'], data['objects_to_advertise'])\n",
        "    advertisers.append(new_advertiser)\n",
        "    unique_objects.update(data['objects_to_advertise'])\n",
        "    update_labels()\n",
        "    return jsonify({\"message\": \"Advertiser added successfully\"}), 201\n",
        "\n",
        "@app.route('/advertisers', methods=['GET'])\n",
        "def get_advertisers():\n",
        "    return jsonify([vars(adv) for adv in advertisers])\n",
        "\n",
        "@app.route('/onboard_meme', methods=['POST'])\n",
        "def onboard_meme():\n",
        "    os.makedirs(\"uploads\", exist_ok=True)\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({\"error\": \"No image file provided\"}), 400\n",
        "\n",
        "    image = request.files['image']\n",
        "    meme_name = request.form.get('name')\n",
        "\n",
        "    if image.filename == '' or not meme_name:\n",
        "        return jsonify({\"error\": \"No selected image file or meme name not provided\"}), 401\n",
        "\n",
        "    if meme_name in memes:\n",
        "        return jsonify({\"error\": \"Meme name already exists\"}), 402\n",
        "\n",
        "    if image and zsod:\n",
        "        image_path = os.path.join('uploads', f\"{meme_name}_{image.filename}\")\n",
        "        image.save(image_path)\n",
        "\n",
        "        img = Image.open(image_path)\n",
        "        print(\"Inside\", img.size)\n",
        "        boxes = zsod.apply_on_image(img)\n",
        "        pred_labels = [box['label'] for box in boxes]\n",
        "        boxes = [[box['box'][l] for l in ['xmin', 'ymin', 'xmax', 'ymax']] for box in boxes]\n",
        "        if len(boxes)==0:\n",
        "          return jsonify({\"error\": \"No objects to detect or image processing failed\"}), 403\n",
        "        masks = cys.segment_array_of_bboxes(boxes, img)\n",
        "        mask_means = [np.mean(mask) for mask in masks]\n",
        "        sorted_items = sorted(zip(mask_means, masks, pred_labels, boxes), key=lambda x: x[0], reverse=True)\n",
        "        sorted_mask_means, sorted_masks, sorted_pred_labels, sorted_boxes = zip(*sorted_items)\n",
        "        sorted_pred_labels = list(sorted_pred_labels)\n",
        "        sorted_boxes = list(sorted_boxes)\n",
        "        sorted_masks = np.stack(list(sorted_masks))\n",
        "\n",
        "        new_meme = Meme(meme_name, image_path, sorted_masks[:4], sorted_pred_labels[:4])\n",
        "        memes[meme_name] = new_meme\n",
        "\n",
        "        return jsonify({\"message\": \"Meme onboarded successfully\", \"meme_name\": meme_name}), 201\n",
        "    else:\n",
        "        return jsonify({\"error\": \"No objects to detect or image processing failed\"}), 403\n",
        "\n",
        "@app.route('/edit_meme/<meme_name>', methods=['POST'])\n",
        "def edit_meme(meme_name):\n",
        "    if meme_name not in memes:\n",
        "        return jsonify({\"error\": \"Meme not found\"}), 404\n",
        "\n",
        "    prompt = request.json.get('prompt', '')\n",
        "\n",
        "    meme = memes[meme_name]\n",
        "    img = Image.open(meme.image_path)\n",
        "    edited_path = f\"edited_{os.path.basename(meme.image_path)}\"\n",
        "    print(len(meme.masks))\n",
        "    fwde.edit_image(img, meme.masks, prompt, meme.pred_labels, [edited_path]*len(meme.masks))\n",
        "    print(edited_path)\n",
        "    return jsonify({\"message\": \"Meme edited successfully\", \"edited_image_path\": edited_path}), 200\n",
        "\n",
        "@app.route('/get_edited_meme/<path:filename>', methods=['GET'])\n",
        "def get_edited_meme(filename):\n",
        "    return send_file(filename, mimetype='image/jpeg')\n",
        "\n",
        "@app.route('/get_meme_as_base64/<meme_name>', methods=['GET'])\n",
        "def get_meme_as_base64(meme_name):\n",
        "    if meme_name not in memes:\n",
        "        return jsonify({\"error\": \"Meme not found\"}), 404\n",
        "\n",
        "    meme = memes[meme_name]\n",
        "    with open(meme.image_path, \"rb\") as image_file:\n",
        "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "    return jsonify({\"image_base64\": encoded_string})\n",
        "\n",
        "@app.route('/get_meme_names', methods=['GET'])\n",
        "def get_meme_names():\n",
        "    return jsonify({\"meme_names\": list(memes.keys())})"
      ],
      "metadata": {
        "id": "_SD0zSEDSihf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    app.run(host='0.0.0.0', port=5000)"
      ],
      "metadata": {
        "id": "f3qSzekQqskU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kzCKZYuDWjQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}